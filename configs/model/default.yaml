n_layers: 8 # Number of transformer layers
diffusion_noise_schedule: cosine # noise schedule for diffusion time
diffusion_steps: 1000 # number of diffusion steps
nu:
    p: 2
hidden_mlp_dims:
    X: 256 # hidden dimension of the MLP for cellular features
    y: 256 # hidden dimension of the MLP for diffusion time
    pos: 64 # hidden dimension of the MLP for position
hidden_dims:
    dx: 256 # hidden dimension of the MLP for cellular features
    dy: 1 # hidden dimension of the MLP for diffusion time
    num_heads: 16 # number of heads in the multi-head attention
    dim_ffX: 256 # hidden dimension of the cellular features feedforward network in the transformer
    dim_ffy: 256 # hidden dimension of the diffusion time feedforward network in the transformer
    dd: 64 # hidden dimension of the MLP for positions
    output_features_to_pos_dims: 4 # hidden dimension of the MLP for the output features to positions